# mT5 Translator
In this project I built Translator using Transfer Learning approach. I used mT5 (multilingual pretrained text-to-text transformer model) and fine-tuned it on 4 downstream tasks (English-German, German-English, Russian-English, English-Russian) using data from
[The Tatoeba Translation Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge).

![](website.gif)

**Tools used:**
* PyTorch
* Hugging Face Transformers
* Colab
* Flask 
* Bootstrap
